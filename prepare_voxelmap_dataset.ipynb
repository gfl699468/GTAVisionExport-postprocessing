{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import visualization\n",
    "import os\n",
    "from gta_math import points_to_homo, ndc_to_view, construct_proj_matrix, view_to_world, construct_view_matrix\n",
    "from visualization import load_depth, save_pointcloud_csv\n",
    "import progressbar\n",
    "from pointcloud_to_voxelmap import pointclouds_to_voxelmap\n",
    "from joblib import Parallel, delayed\n",
    "from configparser import ConfigParser\n",
    "from PIL import Image\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ini_file = \"gta-postprocessing.ini\"\n",
    "visualization.multi_page = False\n",
    "visualization.ini_file = ini_file\n",
    "\n",
    "conn = visualization.get_connection()\n",
    "cur = conn.cursor()\n",
    "\n",
    "CONFIG = ConfigParser()\n",
    "CONFIG.read(ini_file)\n",
    "in_directory = CONFIG[\"Images\"][\"Tiff\"]\n",
    "out_directory = CONFIG[\"Images\"][\"MlDatasetVoxel\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 8438 scenes\n"
     ]
    }
   ],
   "source": [
    "run_id = 6\n",
    "\n",
    "cur.execute(\"\"\"SELECT DISTINCT scene_id \\\n",
    "  FROM snapshots \\\n",
    "  WHERE run_id = {} \\\n",
    "  \"\"\".format(run_id))\n",
    "\n",
    "scenes = []\n",
    "for row in cur:\n",
    "    res = dict(row)\n",
    "    scenes.append(res)\n",
    "\n",
    "print('There are {} scenes'.format(len(scenes)))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### functions for each scene"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class NoMainImageException(Exception):\n",
    "    pass\n",
    "\n",
    "# import time\n",
    "MAX_DISTANCE = 20 # in meters, meaning I care only for point up to 20 meters\n",
    "\n",
    "def get_base_name(name):\n",
    "    return os.path.basename(os.path.splitext(name)[0])\n",
    "\n",
    "\n",
    "def scene_to_pointcloud(cameras):\n",
    "    pointclouds = []\n",
    "    cam_positions = []\n",
    "    \n",
    "    for cam in cameras:\n",
    "        pointcloud = camera_to_pointcloud(cam)\n",
    "        pointclouds.append(pointcloud)\n",
    "        cam_positions.append(cam['camera_pos'])\n",
    "    return pointclouds, cam_positions\n",
    "\n",
    "\n",
    "def get_main_image_name(cameras):\n",
    "    for cam in cameras:\n",
    "        # this is the main camera\n",
    "        if np.array_equal(cam['camera_relative_rotation'], [0, 0, 0]):\n",
    "            return cam['imagepath']\n",
    "    raise NoMainImageException('no main image')\n",
    "\n",
    "    \n",
    "def load_scene_db_data(scene_id):\n",
    "    conn = visualization.get_connection()\n",
    "    cur = conn.cursor()\n",
    "    cur.execute(\"\"\"SELECT snapshot_id, imagepath, cam_near_clip, camera_fov, width, height, \\\n",
    "      ARRAY[st_x(camera_relative_rotation), st_y(camera_relative_rotation), st_z(camera_relative_rotation)] as camera_relative_rotation, \\\n",
    "      ARRAY[st_x(camera_pos), st_y(camera_pos), st_z(camera_pos)] as camera_pos, \\\n",
    "      ARRAY[st_x(camera_rot), st_y(camera_rot), st_z(camera_rot)] as camera_rot \\\n",
    "      FROM snapshots \\\n",
    "      WHERE scene_id = '{}'\n",
    "      ORDER BY timestamp ASC \\\n",
    "    \"\"\".format(scene_id))\n",
    "\n",
    "    cameras = []\n",
    "    for row in cur:\n",
    "        res = dict(row)\n",
    "        res['camera_rot'] = np.array(res['camera_rot'])\n",
    "        res['camera_pos'] = np.array(res['camera_pos'])\n",
    "        res['camera_relative_rotation'] = np.array(res['camera_relative_rotation'])\n",
    "        res['view_matrix'] = construct_view_matrix(res['camera_pos'], res['camera_rot'])\n",
    "        res['proj_matrix'] = construct_proj_matrix(res['height'], res['width'], res['camera_fov'], res['cam_near_clip'])\n",
    "        cameras.append(res)\n",
    "    return cameras\n",
    "\n",
    "\n",
    "def camera_to_pointcloud(cam):\n",
    "    name = cam['imagepath']\n",
    "    depth = load_depth(name)\n",
    "    cam['cam_far_clip'] = MAX_DISTANCE\n",
    "    vecs, _ = points_to_homo(cam, depth)\n",
    "    assert(vecs.shape[0] == 4)\n",
    "    vecs_p = ndc_to_view(vecs, cam['proj_matrix'])\n",
    "    vecs_p_world = view_to_world(vecs_p, cam['view_matrix'])\n",
    "    assert(vecs_p_world.shape[0] == 4)\n",
    "    return vecs_p_world[0:3, :]\n",
    "\n",
    "\n",
    "def scene_to_voxelmap(scene_id):\n",
    "    # start = time.time()\n",
    "    pointclouds, cam_positions = scene_to_pointcloud(scene_id)\n",
    "    # end = time.time()\n",
    "    # print('scene to pointclouds', end - start)\n",
    "    # start = time.time()\n",
    "    assert(pointclouds[0].shape[0] == 3)\n",
    "    voxelmap = pointclouds_to_voxelmap(pointclouds, cam_positions)\n",
    "    # end = time.time()\n",
    "    # print('pointclouds to voxelmap', end - start)\n",
    "\n",
    "    return voxelmap\n",
    "\n",
    "\n",
    "def convert_tiff(in_directory, out_directory, out_name, name):\n",
    "    out_format = 'jpg'\n",
    "    outfile = os.path.join(out_directory, \"{}.{}\".format(out_name, out_format))\n",
    "    if os.path.exists(outfile):\n",
    "        return\n",
    "    try:\n",
    "        infile = os.path.join(in_directory, name)\n",
    "        im = Image.open(infile)\n",
    "        im = im.convert(mode=\"RGB\")\n",
    "        # print(\"Generating new format for {} to new file {}\".format(name, out_name))\n",
    "        im.save(outfile)\n",
    "    except OSError:\n",
    "        # print(\"Skipping invalid file {}\".format(name))\n",
    "        return\n",
    "\n",
    "\n",
    "def convert_scene_to_img_and_voxelmap(in_directory, out_directory, scene_id):\n",
    "    if 'pbar' in globals() and 'counter' in globals():\n",
    "        global counter\n",
    "        counter += 1\n",
    "        pbar.update(counter)\n",
    "\n",
    "    # start = time.time()\n",
    "    cameras = load_scene_db_data(scene_id)\n",
    "    try:\n",
    "        image_name = get_main_image_name(cameras)\n",
    "        # end = time.time()\n",
    "        # print('loading data from db', end - start)\n",
    "        # start = time.time()\n",
    "        convert_tiff(in_directory, out_directory, image_name, image_name+'.tiff')\n",
    "        # end = time.time()\n",
    "        # print('converting tiff to jpg', end - start)\n",
    "        # start = time.time()\n",
    "        outfile = os.path.join(out_directory, \"{}.rick\".format(image_name))\n",
    "        if os.path.exists(outfile):\n",
    "            return\n",
    "        voxelmap = scene_to_voxelmap(cameras)\n",
    "        # end = time.time()\n",
    "        # print('scene to voxelmap', end - start)\n",
    "        # start = time.time()\n",
    "        with open(outfile, 'wb+') as f:\n",
    "            pickle.dump(voxelmap, f)\n",
    "        # end = time.time()\n",
    "        # print('saving voxelmap', end - start)\n",
    "    except NoMainImageException:\n",
    "        print('No main image for scene {}, skipping.'.format(scene_id))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### actually running the extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3% 261 |#                                                         | 165.5 B/s"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No main image for scene 388309dc-568f-43ab-b2c1-86fb809cc570, skipping.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3% 328 |##                                                        |   0.8 B/sC:\\ProgramData\\Anaconda3\\lib\\site-packages\\tifffile\\tifffile.py:2642: RuntimeWarning: py_decodelzw encountered unexpected end of stream\n",
      "  strip = decompress(strip)\n",
      "  4% 412 |##                                                        |   0.4 B/s"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No main image for scene 592377fd-866a-4d81-bdb0-4e63ae584bab, skipping.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  5% 461 |###                                                       |   0.4 B/s"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No main image for scene c70fe8d1-e628-483e-a27a-6a2c7b862857, skipping.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  6% 565 |###                                                       |   0.3 B/s"
     ]
    }
   ],
   "source": [
    "workers = 20\n",
    "\n",
    "widgets = [progressbar.Percentage(), ' ', progressbar.Counter(), ' ', progressbar.Bar(), ' ',\n",
    "           progressbar.FileTransferSpeed()]\n",
    "\n",
    "pbar = progressbar.ProgressBar(widgets=widgets, maxval=len(scenes)).start()\n",
    "counter = 0\n",
    "\n",
    "Parallel(n_jobs=workers, backend='threading')(delayed(convert_scene_to_img_and_voxelmap)(in_directory, out_directory, i['scene_id']) for i in scenes)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### running extraction for one scene"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "convert_scene_to_img_and_voxelmap(in_directory, out_directory, scenes[0]['scene_id'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this is to visualize voxelmap as a pointcloud\n",
    "def voxelmap_to_pointcloud_csv(path_in, path_out):\n",
    "    with open(path_in, 'rb') as f:\n",
    "        voxels, values, voxel_size = pickle.load(f)\n",
    "    voxels = voxels[:, values >= 0]\n",
    "    save_pointcloud_csv(voxels.T, path_out)\n",
    "    \n",
    "\n",
    "def scene_to_pointcloud_csv(scene_id, path_out):\n",
    "    if 'pbar' in globals() and 'counter' in globals():\n",
    "        global counter\n",
    "        counter += 1\n",
    "        pbar.update(counter)\n",
    "\n",
    "    cameras = load_scene_db_data(scene_id)\n",
    "    pointclouds, cam_positions = scene_to_pointcloud(cameras)\n",
    "    big_pointcloud = np.zeros((3, 0))\n",
    "    for pc in pointclouds:\n",
    "        big_pointcloud = np.append(big_pointcloud, pc, axis=1)\n",
    "    save_pointcloud_csv(big_pointcloud.T, path_out)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "voxelmap_to_pointcloud_csv(r'D:\\ml-datasets-voxel\\2018-03-07--15-19-54--505.rick', r'D:\\ml-datasets-voxel\\30m-2018-03-07--15-19-54--505.csv')\n",
    "scene_to_pointcloud_csv(scenes[0]['scene_id'], r'D:\\ml-datasets-voxel\\pc-2018-03-07--15-19-54--505.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
