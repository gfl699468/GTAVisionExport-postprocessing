{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "from extract_consecutive_screenshots import get_pickle_name, load_objects, load_snapshot_data, analyze_run\n",
    "from visualization import get_connection, get_gta_image_jpg_dir\n",
    "from os import path\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "from matplotlib import patches\n",
    "import numpy as np\n",
    "# JPEG_DIR = get_gta_image_jpg_dir()\n",
    "JPEG_DIR = 'D:/GTAV_extraction_output/rgb-jpeg'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def display_snapshots(car, indices=100):\n",
    "    if type(indices) is int:\n",
    "        snapshots_range = (0, indices)\n",
    "    elif type(indices) in [tuple, list]:\n",
    "        snapshots_range = indices        \n",
    "    for snapshot in car['snapshots'][snapshots_range[0]:snapshots_range[1]]:\n",
    "        # print(snapshot)\n",
    "        plt.figure(figsize=(18,18))\n",
    "        img_path = path.join(JPEG_DIR, 'info-' + snapshot['image'] + '-0.jpg')\n",
    "        print(img_path)\n",
    "        img = Image.open(img_path)\n",
    "        size = img.size\n",
    "        bbox = np.array(snapshot['bbox'])\n",
    "        print(size)\n",
    "        bbox[:, 0] *= size[0]\n",
    "        bbox[:, 1] *= size[1]\n",
    "        print(bbox)\n",
    "        width, height = bbox[0, :] - bbox[1, :]\n",
    "        rect = patches.Rectangle(bbox[1, :], width, height, linewidth=1, edgecolor='r', facecolor='none')\n",
    "        # Add the patch to the Axes\n",
    "        plt.gca().add_patch(rect)\n",
    "        \n",
    "        plt.imshow(img)\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "run_id = 52\n",
    "analyze_run(run_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "conn = get_connection()\n",
    "run_id = 52\n",
    "cars = load_objects(run_id)\n",
    "len(cars)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "car = list(cars.values())[4410]\n",
    "len(car['snapshots'])\n",
    "snaps = car['snapshots']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for car in list(cars.values())[4410:4411]:\n",
    "    display_snapshots(car, (0, 20))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "snapshot = car['snapshots'][0]\n",
    "# print(snapshot)\n",
    "bbox = snapshot['bbox']\n",
    "# print(bbox)\n",
    "pos1 = np.array(car['snapshots'][0]['position'])\n",
    "pos2 = np.array(car['snapshots'][1]['position'])\n",
    "print(pos1, pos2)\n",
    "pos2 - pos1\n",
    "snapshot1 = load_snapshot_data(car['snapshots'][0]['snapshot_id'])\n",
    "snapshot2 = load_snapshot_data(car['snapshots'][1]['snapshot_id'])\n",
    "# print(snapshot1, snapshot2)\n",
    "pos1_homo = np.append(pos1, 1)\n",
    "print(pos1_homo)\n",
    "print(snapshot1['view_matrix'])\n",
    "viewed = np.matmul(pos1_homo, snapshot1['view_matrix'])\n",
    "projected = np.matmul(viewed, snapshot1['proj_matrix'])\n",
    "print('viewed', viewed)\n",
    "print('projected', projected)\n",
    "print(viewed / viewed[3])\n",
    "print(projected / projected[3])\n",
    "print(bbox)\n",
    "\n",
    "print(snapshot1['timestamp'])\n",
    "print(snapshot2['timestamp'])\n",
    "print(snapshot2['timestamp'] - snapshot1['timestamp'])\n",
    "print((snapshot2['timestamp'] - snapshot1['timestamp']).total_seconds())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing whether matpltolib displaying works:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import matplotlib\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "'DISPLAY' in os.environ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "img_path = '/datagrid/personal/racinmat/GTA-jpg/info-2017-11-25--01-59-56--393-0.jpg'\n",
    "img = Image.open(img_path)\n",
    "plt.imshow(img)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "exitval = os.system('python -c \"import matplotlib.pyplot as plt; plt.figure()\"')\n",
    "exitval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "arr = [1, 2, 3, 4, 5]\n",
    "arr[4:5]\n",
    "type(cars)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "car"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "list(cars.values())[8]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### playing with coordinates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "fx = 1\n",
    "fy = 1\n",
    "cx = 1\n",
    "cy = 1\n",
    "\n",
    "projection = np.array([\n",
    "    [1, 0, 0, 0],\n",
    "    [0, 1, 0, 0],\n",
    "    [0, 0, 1, 0],\n",
    "])\n",
    "\n",
    "viewport = np.array([\n",
    "    [fx, 0, cx],\n",
    "    [0, fy, cy],\n",
    "    [0, 0,   1],\n",
    "])\n",
    "\n",
    "# vecs_3d = np.eye(3)\n",
    "vec_3d = np.array([\n",
    "    [1, 2, 1, 1], \n",
    "    [1, 1, 2, 1], \n",
    "    [1, 1, 1, 2]\n",
    "])\n",
    "base_homo = np.vstack((vec_3d, np.ones(vec_3d.shape[1])))\n",
    "tmp = np.matmul(projection, base_homo)\n",
    "in_plane = np.matmul(viewport, tmp)\n",
    "in_plane = in_plane[0:2,:] / in_plane[2,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "in_plane[0:2,:] / in_plane[2,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "proj_matrix = [[0.0033408345178822974,0.00000000000541810525481537,-0.000000000003395690385777847,0.000000006448863859587206],\n",
    "               [0.000000000011212100626821622,0.0033408344344528166,0.00000000000223493727864732,-0.00000001733577048579349],\n",
    "                [0.0000000000006709455750076875,-0.000000000003768028993206621,-0.00046103226552438563,0.92717973872632550],\n",
    "               [0.00000000000000000,0.00000000000000000,0.00000000000000000,1.00000000000000000]]\n",
    "proj_matrix = np.array(proj_matrix)\n",
    "view_matrix = [[0.99702072143554690,-0.07713291049003601,0.00000000000000000,3154.52976655940440000],\n",
    "               [0.06535770744085312,0.84481430053710940,0.53105276823043820,-1790.31525175574030000],\n",
    "               [-0.04096164554357529,-0.52947062253952030,0.84733867645263670,1175.29422811363100000],\n",
    "               [0.00000000000000000,0.00000000000000000,0.00000000000000000,1.00000000000000000]]\n",
    "view_matrix = np.array(view_matrix)\n",
    "bbox = np.array([(0.4197019636631012,0.43263527750968933),\n",
    "                 (0.0730963870882988,0.15234601497650146)])\n",
    "bbox3d = np.array([[-1.10799407958984, -2.97677373886108, -0.731413125991821, 0],\n",
    "                  [1.10799407958984, 2.37375974655151, 1.56551647186279, 0]]).T\n",
    "bbox_pos = np.array([-2712.16064453125, 2290.10668945312, 18.4052906036377, 1]).T\n",
    "bbox3d[:,0] += bbox_pos\n",
    "bbox3d[:,1] += bbox_pos\n",
    "print(bbox3d)\n",
    "# bbox3d_cam = np.matmul(view_matrix, np.matmul(proj_matrix, bbox3d))\n",
    "# bbox3d_cam = np.matmul(view_matrix, bbox3d)\n",
    "bbox3d_cam = np.matmul(np.linalg.inv(view_matrix), bbox3d)\n",
    "# bbox3d_cam = np.matmul(proj_matrix, bbox3d)\n",
    "# bbox3d_cam = np.matmul(proj_matrix, np.matmul(view_matrix, bbox3d))\n",
    "print(bbox3d_cam)\n",
    "bbox2d = bbox3d_cam[0:2,:] / bbox3d_cam[2,:]\n",
    "print(bbox2d)\n",
    "fov = 50\n",
    "# bbox2d * fov\n",
    "bbox2d"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### showing consecutive cars sorted by sequence length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "d = {handle: len(car['snapshots']) for handle, car in cars.items()}\n",
    "list(sorted(d.items(), key=lambda x: -x[1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## analyzing one car"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### getting index of car value by its handle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "handle = 504336\n",
    "indices = [key for key, i in enumerate(cars.values()) if i['handle'] == handle]\n",
    "car_index = indices[0]\n",
    "indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_pos_diffs(snapshots):\n",
    "    pos_diffs = []\n",
    "    positions = [snap['position'] for snap in snapshots]\n",
    "    for i in range(1, len(snapshots)):\n",
    "        diff = np.array(positions[i]) - np.array(positions[i - 1])\n",
    "        pos_diffs.append(diff)\n",
    "    return pos_diffs\n",
    "\n",
    "def get_time_diffs(snapshots):\n",
    "    # gets difference in seconds, for normalization\n",
    "    time_diffs = []\n",
    "    times = [snap['timestamp'] for snap in snapshots]\n",
    "    for i in range(1, len(snapshots)):\n",
    "        diff = (times[i] - times[i - 1]).total_seconds()\n",
    "        time_diffs.append(diff)\n",
    "    return time_diffs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from pprint import pprint\n",
    "# car_index = 4405\n",
    "car = list(cars.values())[car_index]\n",
    "pos_diffs = get_pos_diffs(car['snapshots'])\n",
    "time_diffs = get_time_diffs(car['snapshots'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "car['snapshots']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pprint(list(enumerate(pos_diffs)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "snapshot = snaps[0]\n",
    "snapshot\n",
    "# car"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def show_snapshot(snapshot):\n",
    "    img_path = path.join(JPEG_DIR, 'info-' + snapshot['image'] + '-0.jpg')\n",
    "    # print(img_path)\n",
    "    img = Image.open(img_path)\n",
    "    size = img.size\n",
    "    bbox = np.array(snapshot['bbox'])\n",
    "    # print(size)\n",
    "    bbox[:, 0] *= size[0]\n",
    "    bbox[:, 1] *= size[1]\n",
    "    # print(bbox)\n",
    "    width, height = bbox[0, :] - bbox[1, :]\n",
    "    rect = patches.Rectangle(bbox[1, :], width, height, linewidth=1, edgecolor='r', facecolor='none')\n",
    "    # Add the patch to the Axes\n",
    "    plt.figure()\n",
    "    plt.gca().add_patch(rect)        \n",
    "    plt.imshow(img)\n",
    "    plt.show()\n",
    "    \n",
    "def unit_vector(vector):\n",
    "    return vector / np.linalg.norm(vector)\n",
    "\n",
    "def angle_between(v1, v2):\n",
    "    v1_u = unit_vector(v1)\n",
    "    v2_u = unit_vector(v2)\n",
    "    return np.arccos(np.clip(np.dot(v1_u, v2_u), -1.0, 1.0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "show_snapshot(snaps[0])\n",
    "show_snapshot(snaps[1])\n",
    "show_snapshot(snaps[2])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "direction = snapshot['cam_direction']\n",
    "print(direction)\n",
    "direction[0] ** 2 + direction[1] ** 2 + direction[2] ** 2\n",
    "angle_between(pos_diffs[0], snapshot['cam_direction'])\n",
    "angle_between(pos_diffs[0][0:2], snapshot['cam_direction'][0:2])\n",
    "# angle_between([0, 1], [2, 2])\n",
    "# relative = np.matmul(snapshot['view_matrix'], to_homo(pos_diffs[0]))\n",
    "# relative\n",
    "# make one axe perpendicualr to 2D view, and use it as base for transforming the direction to relative one"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# transformation to relative\n",
    "diff = pos_diffs[0]\n",
    "cam = snapshot['cam_direction']\n",
    "base = np.array([\n",
    "    [cam[0], cam[1]],\n",
    "    [cam[1], -cam[0]]\n",
    "])\n",
    "\n",
    "relative = np.matmul(base, diff[0:2])\n",
    "relative"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def transform_to_relative(diff, cam):\n",
    "    base = np.array([\n",
    "        [cam[0], cam[1]],\n",
    "        [cam[1], -cam[0]]\n",
    "    ])\n",
    "    return np.matmul(base, diff[0:2])\n",
    "\n",
    "def normalize_diff(relative_diff, time_diff):\n",
    "    return relative_diff / time_diff\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### calculating and showing all images and their dirs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "car = cars[list(cars.keys())[150]]\n",
    "snaps = car['snapshots']\n",
    "pos_diffs = get_pos_diffs(snaps)\n",
    "time_diffs = get_time_diffs(snaps)\n",
    "\n",
    "for i in range(min(20, len(pos_diffs))):\n",
    "    snap = snaps[i]\n",
    "    print(snap)\n",
    "    diff = pos_diffs[i]\n",
    "    time_diff = time_diffs[i]\n",
    "    show_snapshot(snap)\n",
    "    print('time diff:', time_diff)\n",
    "    diff_relative = transform_to_relative(diff, snap['cam_direction'][0:2])\n",
    "    print('diff_relative:', diff_relative)\n",
    "    diff_normalized = normalize_diff(diff_relative, time_diff)\n",
    "    print('diff_normalized:', diff_normalized)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "diff = pos_diffs[0]\n",
    "cam = snapshot['cam_direction']\n",
    "print('diff:', diff)\n",
    "print('cam:', cam)\n",
    "print('0, 1:', angle_between((diff[0], diff[1]), (cam[0], cam[1])) * (180 / np.pi))\n",
    "print('0, 2:', angle_between((diff[0], diff[2]), (cam[0], cam[2])) * (180 / np.pi))\n",
    "print('1, 2:', angle_between((diff[1], diff[2]), (cam[1], cam[2])) * (180 / np.pi))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib notebook\n",
    "\n",
    "# prepare directions\n",
    "dirs = np.array([s['cam_direction'] for s in snaps])\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(111, projection='3d')\n",
    "# plot directions\n",
    "ax.scatter(dirs[:,0], dirs[:,1], dirs[:,2], s=2, color='r')\n",
    "\n",
    "# plot sphere, for reference\n",
    "u = np.linspace(0, 2 * np.pi, 100)\n",
    "v = np.linspace(0, np.pi, 100)\n",
    "x = 0.9 * np.outer(np.cos(u), np.sin(v))\n",
    "y = 0.9 * np.outer(np.sin(u), np.sin(v))\n",
    "z = 0.9 * np.outer(np.ones(np.size(u)), np.cos(v))\n",
    "ax.plot_surface(x, y, z, color='b')\n",
    "\n",
    "ax.set_aspect('equal')\n",
    "ax.set_xlim(-1, 1)\n",
    "ax.set_ylim(-1, 1)\n",
    "ax.set_zlim(-1, 1)\n",
    "\n",
    "# plt.show()\n",
    "# rotate the axes and update\n",
    "for angle in range(0, 360):\n",
    "    ax.view_init(30, angle)\n",
    "    plt.draw()\n",
    "#    plt.pause(.001)\n",
    "pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import math\n",
    "in_2d = relative[0:2,:] / relative[2,:]\n",
    "math.atan2(in_2d[1], in_2d[0])\n",
    "dirs[:,0]\n",
    "print(dirs)\n",
    "norms = np.linalg.norm(dirs,axis=1)\n",
    "np.max(norms)\n",
    "sphere = np.hstack((x,y,z))\n",
    "norms = np.linalg.norm(sphere,axis=1)\n",
    "np.min(norms)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def to_homo(vec):\n",
    "    if len(vec.shape) == 1:\n",
    "        # need to transform to column vector from row\n",
    "        vec = vec[np.newaxis].T\n",
    "    return np.vstack((pos_diffs[0][np.newaxis].T, np.ones(1)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### testing coordinates transformation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def to_homo(vec):\n",
    "    if len(vec.shape) == 1:\n",
    "        # need to transform to column vector from row\n",
    "        vec = vec[np.newaxis].T\n",
    "\n",
    "    return np.vstack((pos_diffs[0][np.newaxis].T, np.ones(1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "point = snapshot['cam_direction']\n",
    "base = np.array([\n",
    "    [point[0], point[1]],\n",
    "    [point[1], -point[0]]\n",
    "])\n",
    "\n",
    "fig = plt.figure()\n",
    "fig.gca().set_xlim(-1.5, 1.5)\n",
    "fig.gca().set_ylim(-1.5, 1.5)\n",
    "for i in range(0, 100):\n",
    "    j = i*np.pi/200\n",
    "    point = [np.cos(j), np.sin(j)]\n",
    "    fig.gca().scatter(point[0], point[1], s=2, color='r')\n",
    "    # fig.gca().scatter(point[1], -point[0], s=2, color='g')\n",
    "    fig.gca().scatter(-point[1], point[0], s=2, color='g')\n",
    "    plt.draw()\n",
    "    time.sleep(0.1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "snapshot"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## inspecting processed features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "def get_pickle_processed_name(run_id):\n",
    "    return os.path.join('runs', 'run_{}_processed_pickle.rick'.format(run_id))\n",
    "\n",
    "def load_processed_objects(run_id):\n",
    "    data_file = get_pickle_processed_name(run_id)\n",
    "    with open(data_file, 'rb') as file:\n",
    "        return pickle.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "run_id = 52\n",
    "cars = load_processed_objects(run_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cars[list(cars.keys())[0]]['snapshots'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "diffs = np.array([snap['diff_normalized'] for key, car in cars.items() for snap in car['snapshots'] if 'diff_normalized' in snap])\n",
    "diffs[:,0]\n",
    "len(diffs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "plt.scatter(diffs[:,0], diffs[:,1], s=1)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x_range = (-15, 15)\n",
    "y_range = (-15, 15)\n",
    "for "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### playing with depth transformations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2018-03-07--15-19-08--932.tiff\n"
     ]
    }
   ],
   "source": [
    "from configparser import ConfigParser\n",
    "import glob\n",
    "import os\n",
    "from visualization import load_depth\n",
    "from gta_math import ndc_to_real, construct_proj_matrix\n",
    "from PIL import Image\n",
    "\n",
    "def get_base_name(name):\n",
    "    return os.path.basename(os.path.splitext(name)[0])\n",
    "\n",
    "ini_file = \"gta-postprocessing.local.ini\"\n",
    "\n",
    "CONFIG = ConfigParser()\n",
    "CONFIG.read(ini_file)\n",
    "in_directory = CONFIG[\"Images\"][\"Tiff\"]\n",
    "out_directory = CONFIG[\"Images\"][\"MlDataset\"]\n",
    "\n",
    "rgb_format = 'jpg'\n",
    "depth_format = 'png'\n",
    "\n",
    "import visualization\n",
    "visualization.multi_page = False\n",
    "visualization.ini_file = ini_file\n",
    "\n",
    "pattern = '[0-9][0-9][0-9][0-9]-[0-9][0-9]-[0-9][0-9]--[0-9][0-9]-[0-9][0-9]-[0-9][0-9]--[0-9][0-9][0-9].tiff'\n",
    "files = glob.glob(os.path.join(in_directory, pattern))\n",
    "name = files[2000]\n",
    "name = \"2018-03-07--15-19-08--932.tiff\"\n",
    "\n",
    "print(name)\n",
    "\n",
    "conn = visualization.get_connection()\n",
    "cur = conn.cursor()\n",
    "cur.execute(\"\"\"SELECT snapshot_id, imagepath, camera_fov, width, height, cam_near_clip, proj_matrix, view_matrix \\\n",
    "    FROM snapshots \\\n",
    "    WHERE imagepath = '{}' \\\n",
    "    ORDER BY snapshot_id DESC \\\n",
    "    \"\"\".format(name.replace('.tiff', '')))\n",
    "\n",
    "results = [dict(res) for res in cur]\n",
    "#files = [os.path.join(in_directory, i['imagepath']) for i in results]\n",
    "records = [(os.path.join(in_directory, i['imagepath']), \n",
    "            {'H': i['height'], 'W': i['width'], 'fov': i['camera_fov'], 'near_clip': i['cam_near_clip']}) for i in results]\n",
    "res = results[0]\n",
    "\n",
    "infile = os.path.join(in_directory, name)\n",
    "im = Image.open(infile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time to generate_points:  0.015990257263183594\n",
      "time to prepare treshold:  0.07601070404052734\n",
      "time to transfer all points to ndcs:  0.00999593734741211\n"
     ]
    },
    {
     "ename": "MemoryError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mMemoryError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-4-1d0e1c00d0b6>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[0mcalc_proj_matrix\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mconstruct_proj_matrix\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mH\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mW\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfov\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnear_clip\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[0mproj_matrix\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mres\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'proj_matrix'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 8\u001b[1;33m \u001b[0mcalc_new_depth\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mndc_to_real\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdepth\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcalc_proj_matrix\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      9\u001b[0m \u001b[0mnew_depth\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mndc_to_real\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdepth\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mproj_matrix\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Projects\\GTAVisionExport_postprocessing\\gta_math.py\u001b[0m in \u001b[0;36mndc_to_real\u001b[1;34m(depth, proj_matrix)\u001b[0m\n\u001b[0;32m    159\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    160\u001b[0m     \u001b[0mstart\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 161\u001b[1;33m     \u001b[0mvecs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpoints_to_homo\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpoints\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdepth\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtresholding\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    162\u001b[0m     \u001b[0mend\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    163\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'time to points_to_homo: '\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mend\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mstart\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Projects\\GTAVisionExport_postprocessing\\gta_math.py\u001b[0m in \u001b[0;36mpoints_to_homo\u001b[1;34m(points, res, depth, tresholding)\u001b[0m\n\u001b[0;32m     94\u001b[0m     \u001b[0marr\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpoints\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     95\u001b[0m     \u001b[0mvecs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mvalid_points\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 96\u001b[1;33m     \u001b[0mvecs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdepth\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mvalid_points\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     97\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mj\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0marr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     98\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mdepth\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m<=\u001b[0m \u001b[0mthreshold\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mMemoryError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "depth = load_depth(get_base_name(name))\n",
    "H = depth.shape[0]\n",
    "W = depth.shape[1]\n",
    "fov = 50.0\n",
    "near_clip = 1.5\n",
    "calc_proj_matrix = construct_proj_matrix(H, W, fov, near_clip)\n",
    "proj_matrix = np.array(res['proj_matrix'])\n",
    "calc_new_depth = ndc_to_real(depth, calc_proj_matrix)\n",
    "new_depth = ndc_to_real(depth, proj_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib notebook\n",
    "plt.figure(figsize=(10, 10))\n",
    "plt.imshow(im)\n",
    "\n",
    "plt.figure(figsize=(10, 10))\n",
    "plt.imshow(depth)\n",
    "\n",
    "plt.figure(figsize=(10, 10))\n",
    "plt.imshow(new_depth)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "image 2018-03-07--15-19-08--932.tiff projected\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'calc_vecs_p' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-5-81f1361eb098>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     17\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     18\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'image {} projected'\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 19\u001b[1;33m \u001b[0msave_csv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcalc_vecs_p\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mget_base_name\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     20\u001b[0m \u001b[0msave_csv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvecs_p\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'db_'\u001b[0m\u001b[1;33m+\u001b[0m\u001b[0mget_base_name\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'calc_vecs_p' is not defined"
     ]
    }
   ],
   "source": [
    "from gta_math import generate_points, points_to_homo, ndc_to_view, view_to_world\n",
    "import numpy as np\n",
    "\n",
    "def save_csv(vecs_p, name):\n",
    "    a = np.asarray(vecs_p[0:3, :].T)\n",
    "    np.savetxt(\"points-{}.csv\".format(name), a, delimiter=\",\")\n",
    "    \n",
    "width = depth.shape[1]\n",
    "height = depth.shape[0]\n",
    "points = generate_points(width, height)\n",
    "params = {\n",
    "    'width': width,\n",
    "    'height': height,\n",
    "    'proj_matrix': proj_matrix,\n",
    "    'cam_far_clip': 800\n",
    "}\n",
    "\n",
    "print('image {} projected'.format(name))\n",
    "save_csv(calc_vecs_p, get_base_name(name))\n",
    "save_csv(vecs_p, 'db_'+get_base_name(name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "world_vecs_p = view_to_world(vecs_p, res['view_matrix'])\n",
    "save_csv(world_vecs_p, 'world_'+get_base_name(name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time to prepare treshold:  0.0719902515411377\n",
      "time to transfer all points to ndcs:  0.010009050369262695\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "index 1080 is out of bounds for axis 0 with size 1080",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-6-94d4ad7616a7>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mvecs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpoints_to_homo\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpoints\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdepth\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtresholding\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mD:\\Projects\\GTAVisionExport_postprocessing\\gta_math.py\u001b[0m in \u001b[0;36mpoints_to_homo\u001b[1;34m(points, res, depth, tresholding)\u001b[0m\n\u001b[0;32m     94\u001b[0m     \u001b[0marr\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpoints\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     95\u001b[0m     \u001b[0mvecs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mvalid_points\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 96\u001b[1;33m     \u001b[0mvecs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdepth\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mvalid_points\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     97\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mj\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0marr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     98\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mdepth\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m<=\u001b[0m \u001b[0mthreshold\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mIndexError\u001b[0m: index 1080 is out of bounds for axis 0 with size 1080"
     ]
    }
   ],
   "source": [
    "vecs = points_to_homo(points, params, depth, tresholding=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "count lesser than threshold:  391943\n",
      "threshold:  [ 0.00172532]\n",
      "depth min:  0.0\n",
      "depth max:  0.467635\n"
     ]
    }
   ],
   "source": [
    "max_depth = params['cam_far_clip']\n",
    "vec = proj_matrix @ np.array([[1], [1], [-max_depth], [1]])\n",
    "# print(vec)\n",
    "vec /= vec[3]\n",
    "threshold = vec[2]\n",
    "lesser = np.count_nonzero(depth <= threshold)\n",
    "print('count lesser than threshold: ', lesser)\n",
    "print('threshold: ', threshold)\n",
    "print('depth min: ', np.min(depth))\n",
    "print('depth max: ', np.max(depth))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.shape(np.where(depth <= threshold))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.array(np.where(depth >= threshold))[:, 0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'pixels_to_ndcs' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-9-e03713f25305>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mvalid_points\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwhere\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdepth\u001b[0m \u001b[1;33m>\u001b[0m \u001b[0mthreshold\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m \u001b[0mndcs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpixels_to_ndcs\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalid_points\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msize\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      6\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[0mi\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'pixels_to_ndcs' is not defined"
     ]
    }
   ],
   "source": [
    "from gta_math import pixel_to_ndc\n",
    "vecs = np.zeros((4, len(np.where(depth[points[:, 0], points[:, 1]] > threshold)[\n",
    "                            0])))  # this one is used when ommiting 0 depth (point behind the far clip)\n",
    "\n",
    "valid_points = np.array(np.where(depth > threshold))\n",
    "ndcs = pixels_to_ndcs(valid_points, size)\n",
    "\n",
    "i = 0\n",
    "vecs[3, :] = 1  # last, homogenous coordinate\n",
    "arr = points\n",
    "vecs[0:2, :] = valid_points\n",
    "vecs[2, :] = depth[valid_points]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
